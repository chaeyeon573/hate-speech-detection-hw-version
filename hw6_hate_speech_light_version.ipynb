{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949f5d25-b792-4cd2-9da6-ef8714074eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.44.2 in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Requirement already satisfied: tokenizers==0.19.1 in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
      "Collecting accelerate==0.33.0\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting datasets==3.0.1\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting scikit-learn==1.4.2\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.33.0) (2.3.1+cu121)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (22.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.0.1)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.13.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.0.1) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (2024.7.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.33.0) (2.1.5)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==3.0.1)\n",
      "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.1) (1.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.33.0) (1.3.0)\n",
      "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Installing collected packages: dill, scikit-learn, multiprocess, accelerate, datasets\n",
      "\u001b[2K  Attempting uninstall: dill\n",
      "\u001b[2K    Found existing installation: dill 0.4.0\n",
      "\u001b[2K    Uninstalling dill-0.4.0:\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.0\n",
      "\u001b[2K  Attempting uninstall: scikit-learn\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.2\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.2:\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.2\n",
      "\u001b[2K  Attempting uninstall: multiprocessâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: accelerateâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Found existing installation: accelerate 1.12.0â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling accelerate-1.12.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.12.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: datasets\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/5\u001b[0m [accelerate]\n",
      "\u001b[2K    Found existing installation: datasets 4.4.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/5\u001b[0m [accelerate]\n",
      "\u001b[2K    Uninstalling datasets-4.4.1:\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/5\u001b[0m [accelerate]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.4.10mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/5\u001b[0m [accelerate]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5/5\u001b[0m [datasets]4/5\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-0.33.0 datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 scikit-learn-1.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U --no-cache-dir \\\n",
    "  transformers==4.44.2 \\\n",
    "  tokenizers==0.19.1 \\\n",
    "  accelerate==0.33.0 \\\n",
    "  datasets==3.0.1  \\\n",
    "  scikit-learn==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3722ce92-3ed7-4eac-9be1-3a9e221d2853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8141bc50924ed3a547201a99fabc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4101ff6820b74ad88f383e0fbaf2f313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "kmhas_korean_hate_speech.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since jeanlee/kmhas_korean_hate_speech couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/jeanlee___kmhas_korean_hate_speech/default/1.0.0/c657d15baf277c48d467f0625f7d33c50d4352ef (last modified on Sat Dec 13 17:39:23 2025).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"jeanlee/kmhas_korean_hate_speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a728364-3e2d-41e4-b832-7545d07ed9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since jeanlee/kmhas_korean_hate_speech couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/jeanlee___kmhas_korean_hate_speech/default/1.0.0/c657d15baf277c48d467f0625f7d33c50d4352ef (last modified on Sun Dec 14 00:57:37 2025).\n",
      "Using the latest cached version of the dataset since jeanlee/kmhas_korean_hate_speech couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/jeanlee___kmhas_korean_hate_speech/default/1.0.0/c657d15baf277c48d467f0625f7d33c50d4352ef (last modified on Sun Dec 14 00:57:37 2025).\n",
      "Using the latest cached version of the dataset since jeanlee/kmhas_korean_hate_speech couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/jeanlee___kmhas_korean_hate_speech/default/1.0.0/c657d15baf277c48d467f0625f7d33c50d4352ef (last modified on Sun Dec 14 00:57:37 2025).\n"
     ]
    }
   ],
   "source": [
    "# load train, validation, and test dataset from HuggingFace\n",
    "\n",
    "train = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"train\")\n",
    "validation = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"validation\")\n",
    "test = load_dataset(\"jeanlee/kmhas_korean_hate_speech\", split=\"test\")\n",
    "\n",
    "\n",
    "# ðŸ”½ ì›í•˜ëŠ” í¬ê¸°ë¡œ ì¤„ì´ê¸°\n",
    "train_n = 15000\n",
    "val_n   = 1500\n",
    "test_n  = 3000\n",
    "\n",
    "train = train.shuffle(seed=42).select(range(min(train_n, len(train))))\n",
    "validation = validation.shuffle(seed=42).select(range(min(val_n, len(validation))))\n",
    "test = test.shuffle(seed=42).select(range(min(test_n, len(test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564e985-33cf-42f7-b698-d5cf9e2ada19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3edecf1-d181-4e8b-84f5-77f959874243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(example):\n",
    "    labels = example[\"label\"]\n",
    "    example[\"y\"] = 0 if labels ==[8] else 1\n",
    "    return example\n",
    "\n",
    "ds_bin = ds.map(to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0fef0e2-8d84-414a-8cb8-04a7bb9dee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "PATTERN = re.compile(\n",
    " r\"(ã……ã…‚|ã…‚ã……|ã…ˆã„´|ì”¨ë°œ|ë³‘ì‹ |ê°œìƒˆ|ì¢†|ì§€ëž„|ë¯¸ì¹œ|í‹€ë”±|ë§˜ì¶©|ê¹€ì¹˜ë…€|í•œë‚¨)\"\n",
    ")\n",
    "\n",
    "\n",
    "def baseline_predict(text: str) -> int:\n",
    "    return 1 if PATTERN.search(text) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ff5a1b4-83ed-4143-9aa8-3eb7c96f9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "dev = ds_bin[\"validation\"]\n",
    "\n",
    "y_true = dev[\"y\"]\n",
    "y_pred_baseline = [baseline_predict(t) for t in dev[\"text\"]]\n",
    "\n",
    "\n",
    "acc_b = accuracy_score(y_true, y_pred_baseline)\n",
    "\n",
    "f1_macro_b = f1_score(y_true, y_pred_baseline, average=\"macro\")\n",
    "f1_micro_b = f1_score(y_true, y_pred_baseline, average=\"micro\")\n",
    "f1_weighted_b =  f1_score(y_true, y_pred_baseline, average=\"weighted\")\n",
    "precision_macro_b =  precision_score(y_true, y_pred_baseline, average = \"macro\", zero_division= 0)\n",
    "recall_macro_b= recall_score(y_true, y_pred_baseline, average = \"macro\", zero_division = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea81a62-c551-4d8e-9de1-99d5250cc97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63d1b3e7-288f-4885-90c9-1742383deb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"monologg/koelectra-base-v3-discriminator\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def train_only(\n",
    "    model_name,\n",
    "    ds_bin,\n",
    "    out_dir,\n",
    "    max_length,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    lr,\n",
    "    fp16=True\n",
    "):\n",
    "    from transformers import (\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSequenceClassification,\n",
    "        Trainer,\n",
    "        TrainingArguments\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=2\n",
    "    )\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "    ds_tok = ds_bin.map(tokenize, batched=True)\n",
    "    ds_tok = ds_tok.rename_column(\"y\", \"labels\")\n",
    "    ds_tok.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=out_dir,\n",
    "        do_train=True,\n",
    "        do_eval=False,                 # ðŸ”´ eval ì•ˆ í•¨\n",
    "        evaluation_strategy=\"no\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        learning_rate=lr,\n",
    "        fp16=fp16,\n",
    "        logging_steps=100,\n",
    "        report_to=\"none\",\n",
    "        save_safetensors=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=ds_tok[\"train\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(out_dir)\n",
    "\n",
    "    tokenizer.save_pretrained(out_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c88ae6fd-2350-4a76-a7d7-e2639a3b930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ed1f333a884100aabf5512784934bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78977 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea096fc937f4e7eb362e5743b5a7ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6feb76aa604aec9cdc9874aa06a16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21939 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4937' max='4937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4937/4937 04:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.619900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.481800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.367400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.372800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.346300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.327600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.341800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.334300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.288300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.289300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.289300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.259800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.276900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.287800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.322400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.257800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.288700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.288900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.293700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.262200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.264900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.270800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "results = []\n",
    "\n",
    "for m in models:\n",
    "    if \"large\" in m.lower():\n",
    "        bs, ml = 2, 96\n",
    "    else:\n",
    "        bs, ml = 16, 64\n",
    "\n",
    "    out_dir = (\n",
    "        f\"./runs/\"\n",
    "        f\"{m.replace('/','_')}\"\n",
    "        f\"_train-ds-small\"\n",
    "        f\"_ep1\"\n",
    "        f\"_lr2e-5\"\n",
    "    )\n",
    "\n",
    "    # ---------- TRAIN ----------\n",
    "    if not os.path.exists(out_dir):\n",
    "        train_only(\n",
    "            model_name=m,\n",
    "            ds_bin=ds_bin,\n",
    "            out_dir=out_dir,\n",
    "            max_length=ml,\n",
    "            batch_size=bs,\n",
    "            epochs=1,\n",
    "            lr=2e-5,\n",
    "        )\n",
    "\n",
    "\n",
    "#pd.DataFrame(results).sort_values(\"test_f1_macro\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db81273c-8853-42fb-8dda-6dda8434d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "  #  probs = 1 / (1 + np.exp(-logits)) if logits.shape[1] == 1 else None\n",
    "\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    out = {\n",
    "        \"acc\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "        \"precision_macro\": precision_score(labels, preds, average = \"macro\", zero_division= 0),\n",
    "        \"recall_macro\": recall_score(labels, preds, average = \"macro\", zero_division = 0)\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "147e8614-a9c5-423b-916f-10dcf3bedcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_only(model_dir, ds_bin, split, max_length, batch_size):\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "\n",
    "    ds_split = ds_bin[split].map(tokenize, batched=True)\n",
    "    ds_split = ds_split.rename_column(\"y\", \"labels\")\n",
    "    ds_split.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"./eval_tmp\",\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        eval_dataset=ds_split,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    return trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc150f86-5cdc-42cc-8e68-cfb2cfe5e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='549' max='549' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [549/549 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1372' max='1372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1372/1372 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for m in models:\n",
    "    if \"large\" in m.lower():\n",
    "        bs, ml = 2, 96\n",
    "    else:\n",
    "        bs, ml = 16, 64\n",
    "\n",
    "    out_dir = (\n",
    "        f\"./runs/\"\n",
    "        f\"{m.replace('/','_')}\"\n",
    "        f\"_train-ds-small\"\n",
    "        f\"_ep1\"\n",
    "        f\"_lr2e-5\"\n",
    "    )\n",
    "\n",
    "    # ---------- EVAL ----------\n",
    "    val_metrics = eval_only(out_dir, ds_bin, \"validation\", ml, bs)\n",
    "    test_metrics = eval_only(out_dir, ds_bin, \"test\", ml, bs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b145661a-7e58-42f5-93c5-4cd88ea2581e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>out_dir</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>val_f1_micro</th>\n",
       "      <th>val_f1_weighted</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1_micro</th>\n",
       "      <th>val_precision_macro</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>val_recall_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monologg/koelectra-base-v3-discriminator</td>\n",
       "      <td>./runs/monologg_koelectra-base-v3-discriminato...</td>\n",
       "      <td>0.885286</td>\n",
       "      <td>0.888874</td>\n",
       "      <td>0.887078</td>\n",
       "      <td>0.886917</td>\n",
       "      <td>0.886917</td>\n",
       "      <td>0.887078</td>\n",
       "      <td>0.887078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>monologg/koelectra-base-v3-discriminator</td>\n",
       "      <td>./runs/monologg_koelectra-base-v3-discriminato...</td>\n",
       "      <td>0.885286</td>\n",
       "      <td>0.888874</td>\n",
       "      <td>0.887078</td>\n",
       "      <td>0.886917</td>\n",
       "      <td>0.889549</td>\n",
       "      <td>0.887078</td>\n",
       "      <td>0.889557</td>\n",
       "      <td>0.889557</td>\n",
       "      <td>0.886508</td>\n",
       "      <td>0.888934</td>\n",
       "      <td>0.884299</td>\n",
       "      <td>0.888816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model  \\\n",
       "0  monologg/koelectra-base-v3-discriminator   \n",
       "1  monologg/koelectra-base-v3-discriminator   \n",
       "\n",
       "                                             out_dir  val_f1_macro  \\\n",
       "0  ./runs/monologg_koelectra-base-v3-discriminato...      0.885286   \n",
       "1  ./runs/monologg_koelectra-base-v3-discriminato...      0.885286   \n",
       "\n",
       "   test_f1_macro  val_f1_micro  val_f1_weighted  test_f1_weighted   val_acc  \\\n",
       "0       0.888874      0.887078         0.886917          0.886917  0.887078   \n",
       "1       0.888874      0.887078         0.886917          0.889549  0.887078   \n",
       "\n",
       "   test_acc  test_f1_micro  val_precision_macro  test_precision_macro  \\\n",
       "0  0.887078            NaN                  NaN                   NaN   \n",
       "1  0.889557       0.889557             0.886508              0.888934   \n",
       "\n",
       "   val_recall_macro  test_recall_macro  \n",
       "0               NaN                NaN  \n",
       "1          0.884299           0.888816  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results\n",
    "results.append({\n",
    "    \"model\": m,\n",
    "    \"out_dir\": out_dir,\n",
    "\n",
    "    # ---- F1 scores ----\n",
    "    \"val_f1_macro\": val_metrics[\"eval_f1_macro\"],\n",
    "    \"test_f1_macro\": test_metrics[\"eval_f1_macro\"],\n",
    "\n",
    "    \"val_f1_micro\": val_metrics[\"eval_f1_micro\"],\n",
    "    \"test_f1_micro\": test_metrics[\"eval_f1_micro\"],\n",
    "\n",
    "    \"val_f1_weighted\": val_metrics[\"eval_f1_weighted\"],\n",
    "    \"test_f1_weighted\": test_metrics[\"eval_f1_weighted\"],\n",
    "\n",
    "    # ---- Accuracy ----\n",
    "    \"val_acc\": val_metrics[\"eval_acc\"],\n",
    "    \"test_acc\": test_metrics[\"eval_acc\"],\n",
    "\n",
    "    # ---- Precision / Recall (macro) ----\n",
    "    \"val_precision_macro\": val_metrics.get(\"eval_precision_macro\"),\n",
    "    \"test_precision_macro\": test_metrics.get(\"eval_precision_macro\"),\n",
    "\n",
    "    \"val_recall_macro\": val_metrics.get(\"eval_recall_macro\"),\n",
    "    \"test_recall_macro\": test_metrics.get(\"eval_recall_macro\"),\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af73fff4-69b1-4c59-953c-123bc9be205f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e4d1ff8-fe47-4741-943c-ce86bbfef0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    \"model\": \"Baseline (keyword)\",\n",
    "    \"out_dir\": \"N/A\",\n",
    "\n",
    "    \"val_f1_macro\": None,\n",
    "    \"test_f1_macro\": f1_macro_b,\n",
    "\n",
    "    \"val_f1_micro\": None,\n",
    "    \"test_f1_micro\": f1_micro_b,\n",
    "\n",
    "    \"val_f1_weighted\": None,\n",
    "    \"test_f1_weighted\": f1_weighted_b,\n",
    "\n",
    "    \"val_acc\": None,\n",
    "    \"test_acc\": acc_b,\n",
    "\n",
    "    \"val_precision_macro\": None,\n",
    "    \"test_precision_macro\": precision_macro_b,\n",
    "\n",
    "    \"val_recall_macro\": None,\n",
    "    \"test_recall_macro\": recall_macro_b,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98ccadbf-4144-4c22-8bdf-c94588bb6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df = df.round(4)\n",
    "df.to_csv(\"results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807463b-54eb-4adc-bc13-62b645b214ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>out_dir</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>val_f1_micro</th>\n",
       "      <th>val_f1_weighted</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1_micro</th>\n",
       "      <th>val_precision_macro</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>val_recall_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monologg/koelectra-base-v3-discriminator</td>\n",
       "      <td>./runs/monologg_koelectra-base-v3-discriminato...</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>monologg/koelectra-base-v3-discriminator</td>\n",
       "      <td>./runs/monologg_koelectra-base-v3-discriminato...</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.888934</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>0.8888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline (keyword)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.7531514082664958,)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline (keyword)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.7531514082664958,)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline (keyword)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model  \\\n",
       "0  monologg/koelectra-base-v3-discriminator   \n",
       "1  monologg/koelectra-base-v3-discriminator   \n",
       "2                        Baseline (keyword)   \n",
       "3                        Baseline (keyword)   \n",
       "4                        Baseline (keyword)   \n",
       "\n",
       "                                             out_dir  val_f1_macro  \\\n",
       "0  ./runs/monologg_koelectra-base-v3-discriminato...        0.8853   \n",
       "1  ./runs/monologg_koelectra-base-v3-discriminato...        0.8853   \n",
       "2                                                N/A           NaN   \n",
       "3                                                N/A           NaN   \n",
       "4                                                N/A           NaN   \n",
       "\n",
       "   test_f1_macro  val_f1_micro  val_f1_weighted  test_f1_weighted  val_acc  \\\n",
       "0         0.8889        0.8871           0.8869            0.8869   0.8871   \n",
       "1         0.8889        0.8871           0.8869            0.8895   0.8871   \n",
       "2         0.4773           NaN              NaN            0.5069      NaN   \n",
       "3         0.4773           NaN              NaN            0.5069      NaN   \n",
       "4         0.4773           NaN              NaN            0.5069      NaN   \n",
       "\n",
       "   test_acc  test_f1_micro  val_precision_macro   test_precision_macro  \\\n",
       "0    0.8871            NaN                  NaN                    NaN   \n",
       "1    0.8896         0.8896               0.8865               0.888934   \n",
       "2    0.6067         0.6067                  NaN  (0.7531514082664958,)   \n",
       "3    0.6067         0.6067                  NaN  (0.7531514082664958,)   \n",
       "4    0.6067         0.6067                  NaN               0.753151   \n",
       "\n",
       "   val_recall_macro  test_recall_macro  \n",
       "0               NaN                NaN  \n",
       "1            0.8843             0.8888  \n",
       "2               NaN             0.5573  \n",
       "3               NaN             0.5573  \n",
       "4               NaN             0.5573  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "def get_model_preds(model_dir, ds_bin, split, max_length=64, batch_size=16):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "\n",
    "    ds_split = ds_bin[split].map(tokenize, batched=True)\n",
    "    ds_split = ds_split.rename_column(\"y\", \"labels\")\n",
    "    ds_split.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"./pred_tmp\",\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(model=model, args=args, tokenizer=tokenizer)\n",
    "\n",
    "    pred_out = trainer.predict(ds_split)\n",
    "    logits = pred_out.predictions\n",
    "    preds = np.argmax(logits, axis=-1)  # âœ… ë„ˆê°€ ë¬¼ì–´ë³¸ ê·¸ argmaxê°€ ì—¬ê¸°ì„œ ì”€\n",
    "\n",
    "    # (ì˜µì…˜) class=1 í™•ë¥ ë„ ê°™ì´ ë½‘ê¸° (softmax)\n",
    "    exps = np.exp(logits - logits.max(axis=1, keepdims=True))\n",
    "    probs = exps / exps.sum(axis=1, keepdims=True)\n",
    "    prob_hate = probs[:, 1]  # label=1 í™•ë¥ \n",
    "\n",
    "    return preds, prob_hate\n",
    "\n",
    "def make_compare_df(ds_bin, split, model_dir, max_length=64, batch_size=16):\n",
    "    texts = ds_bin[split][\"text\"]\n",
    "    gold  = np.array(ds_bin[split][\"y\"])\n",
    "\n",
    "    baseline = np.array([baseline_predict(t) for t in texts])\n",
    "\n",
    "    model_pred, model_prob = get_model_preds(\n",
    "        model_dir=model_dir,\n",
    "        ds_bin=ds_bin,\n",
    "        split=split,\n",
    "        max_length=max_length,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": texts,\n",
    "        \"gold\": gold,\n",
    "        \"baseline\": baseline,\n",
    "        \"model\": model_pred,\n",
    "        \"model_prob_hate\": model_prob\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "df_test = make_compare_df(\n",
    "    ds_bin=ds_bin,\n",
    "    split=\"test\",\n",
    "    model_dir=\"./runs/monologg_koelectra-base-v3-discriminator_train-ds-small_ep1_lr2e-5\",\n",
    "    max_length=64,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "diff_bm = df_test[df_test[\"baseline\"] != df_test[\"model\"]].copy()\n",
    "diff_bm.sort_values(\"model_prob_hate\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_gm = df_test[df_test[\"gold\"] != df_test[\"model\"]].copy()\n",
    "diff_gm.sort_values(\"model_prob_hate\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3 = diff_bm.sample(3, random_state=42)\n",
    "sample3[[\"text\", \"gold\", \"baseline\", \"model\", \"model_prob_hate\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
